# Snakemake

Snakemake and Cookiecutter are often used in metagenomics to create
workflows and pipelines for analyzing and processing large amounts of
data.

Example workflow: MÃ¶lder F, Jablonski KP, Letcher B et al. Sustainable data analysis with Snakemake [version 2]. F1000Research 2021, 10:33 (doi: 10.12688/f1000research.29032.2)
<img width="666" alt="image" src="https://github.com/UC-Boulder/metagenomics_data_processing/assets/104112036/2b89383a-73d5-4279-88fc-244bb4ed1b49">

![image](https://github.com/UC-Boulder/metagenomics_data_processing/assets/104112036/18d795e7-1b76-4472-be8b-e7bbc6ab2da4)


[Snakemake](https://f1000research.com/articles/10-33/v1) is a workflow
management system that allows users to define rules for executing tasks
and managing dependencies between them. This makes it easier to handle
complex workflows and ensures that tasks are executed in the correct
order.

[Cookiecutter](https://github.com/cookiecutter/cookiecutter)is a tool
for creating project templates, and there are several Cookiecutter
templates available for Snakemake workflows in metagenomics. These
templates provide a basic structure for organizing code and data and can
help streamline the development of new workflows.

## Setting up Snakemake 

To use snakemake, you to have a profile setup called slurm in your
.config. Mine is located at on my cluster:
`/home/emye7956/.config/snakemake`

I used [cookiecutter](https://github.com/Snakemake-Profiles/slurm) to
create a profile. This cookiecutter provides a template Snakemake
profile for configuring Snakemake to run on the [SLURM Workload
Manager](https://slurm.schedmd.com/). The profile defines the following
scripts (which will be saved to your version of my
`/home/emye7956/.config/snakemake` directory).

`slurm-submit.py` - submits a jobscript to slurm

`slurm-jobscript.sh` - a template jobscript

`slurm-status.py` - checks the status of jobs in slurm

`slurm-sidecar.py` - run a Snakemake cluster sidecar for caching queries
to Slurm's controller/database daemons

and a configuration file `config.yaml` that defines default values for
snakemake command line arguments.

### Step1: Log onto Alpine

```
$ ssh emye7956@login.rc.colorado.edu
$ acompile -n 4 --time=2:20
$ cd ~/.config
```

### Step2: Use the cookie cutter steps to set up a profile:

create config directory that snakemake searches for profiles (or use something else)
```
profile_dir="${HOME}/.config/snakemake"
mkdir -p "$profile_dir"
```

use cookiecutter to create the profile in the config directory
```
template="gh:Snakemake-Profiles/slurm"
cookiecutter --output-dir "$profile_dir" "$template"
```

Once you run the above command, there will be a bunch of settings for you to walk through. Choose the following for each:
`profile_name [slurm]: slurm`
`Select use_singularity:
1 - False`
`Select use_conda:
2 - True`
`jobs [500]: `
`restart_times [0]: `
`max_status_checks_per_second [10]: `
`max_jobs_per_second [10]: `
`latency_wait [5]: `
`Select print_shell_commands:
2 - True`
`sbatch_defaults []: `
`cluster_sidecar_help [Use cluster sidecar. NB! Requires snakemake >= 7.0! Enter to continue...]: 
Select cluster_sidecar:
1 - yes`
`cluster_name []: Alpine`
`cluster_jobname [%r_%w]: `
`cluster_logpath [logs/slurm/%r/%j]: `

If this worked correctly, you should be able to see the snakemake/slurm profile in your home config, and if you enter it and type `ls` you should see the following files: 
```
`config.yaml`      
`settings.json`      
`slurm-sidecar.py`  
`slurm-submit.py`
`CookieCutter.py`
`slurm-jobscript.sh`
`slurm-status.py`  
`slurm_utils.py`
```
Don't worry, you won't have to really know what they do until you get to more advanced optimization settings of snakemake. I do highly recommend going to the snakemake webpage and working through some of their documentation and tutorials to get an idea of what's possible with this tool!

### Step 3: Write your snakefile 

Great, now in order to run snakemake, you will need to make a snakemake file with all the "rules" to run it, which are essentially individual batch jobs. Snakemake kind of works in reverse. So you will type the output you want, and snakemake will find the corresponding rule in your and use these steps to convert your specified input into an output. 

You can look at an example of mine, which is called ["snakefile"]https://github.com/UC-Boulder/metagenomics_data_processing/blob/main/3.computer_cluster/snakefile_examples/fastqc1_on_untrimmed. But let's unpack it a bit more here:

Say I want to run Fastqc (will add trimmomatic, kraken and humann3 etc), I would specify a fastqc rule in my snake file. This specifies the inputs, the enviroments to use, the commands to run and the expected output format to recieve.

```
rule fastqc:
    input:
        FORWARD=f"/scratch/alpine/emye7956/mothersmilk/all_qzs/{{sample}}_1.fq.gz",
        REVERSE=f"/scratch/alpine/emye7956/mothersmilk/all_qzs/{{sample}}_2.fq.gz"
    output:
        directory(f"/scratch/alpine/emye7956/mothersmilk/emilys-snake-output-fastqc/{{sample}}")
    conda:
        "qc_env_with_fastqc_and_multiqc"
    resources:
        mem_mb=30000, # MB
        partition="amilan",
        slurm_extra="--nodes=1 --qos=normal --time=20:00:00 --ntasks=8 --mail-type=ALL --mail-user=emye7956@colorado.edu"
    threads: 8
    shell:
        """
        mkdir -p /scratch/alpine/emye7956/mothersmilk/emilys-snake-output-fastqc
        mkdir -p {output}
        fastqc --threads 8 {input.FORWARD} {input.REVERSE} -o {output} || echo {wildcards.sample} >> nzs.txt
        """
```
More info on the rule above:

`input` specifies what should be used as an input when this rule is run.
`output` specifies what the output will look like and where it will be.
`conda:` which conda environent to use. The way it's written above assumes that environment already exists. Otherwise you can put the environment yaml folder there and snakemake will make it. 
`resources:` specifications for the cluster you are using
`shell:` the actual commants you want snakemake to run. Here my shell is creating the output directory, then running fastqc. Any file that for some reason isn't run, will get written to an existing text folder called "nzs.txt" (so I can deal with them individually). 

### Step 4: Run snakemake

To run snakemake, you will need to first activate it, and then run one of the rules specified in the snakefile. Here's an example: 
```
$ module load anaconda
$ conda install -n base -c conda-forge mamba
$ conda activate base
$ mamba create -c conda-forge -c bioconda -n snakemake snakemake
$ conda activate snakemake
```
Once activated, say I wanted to run fasttqc on my samples, I would start by calling snakemake, and then typing the output I want it to make.
```
$snakemake /scratch/alpine/emye7956/mothersmilk/emilys-snake-output-fastqc{sample} -j 1 --cluster "sbatch" --use-conda; done
``` 
Snakemake will then go through the snakefile looking for this output, and run the rule to produce it. 

Now imagine VERY likely scenarios where there is a clitch in the internet, your cluster session times out or your computer dies while your samples are running. You'll want to pick up where you left off. You can so this by running:

```
snakemake --unlock && snakemake --use-conda -j 20 --cluster "sbatch" --rerun-incomplete
```
The unlock is because snakemake closes the diectory with all its depent files when you get interrupted and you need to unlock things to proceed.



