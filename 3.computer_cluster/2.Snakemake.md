# Snakemake

Snakemake and Cookiecutter are often used in metagenomics to create
workflows and pipelines for analyzing and processing large amounts of
data.

[Snakemake](https://f1000research.com/articles/10-33/v1) is a workflow
management system that allows users to define rules for executing tasks
and managing dependencies between them. This makes it easier to handle
complex workflows and ensures that tasks are executed in the correct
order.

[Cookiecutter](https://github.com/cookiecutter/cookiecutter)is a tool
for creating project templates, and there are several Cookiecutter
templates available for Snakemake workflows in metagenomics. These
templates provide a basic structure for organizing code and data and can
help streamline the development of new workflows.

## Setting up Snakemake 

To use snakemake, you to have a profile setup called slurm in your
.config. Mine is located at on my cluster:
`/home/emye7956/.config/snakemake`

I used [cookiecutter](https://github.com/Snakemake-Profiles/slurm) to
create a profile. This cookiecutter provides a template Snakemake
profile for configuring Snakemake to run on the [SLURM Workload
Manager](https://slurm.schedmd.com/). The profile defines the following
scripts (which will be saved to your version of my
`/home/emye7956/.config/snakemake` directory).

`slurm-submit.py` - submits a jobscript to slurm

`slurm-jobscript.sh` - a template jobscript

`slurm-status.py` - checks the status of jobs in slurm

`slurm-sidecar.py` - run a Snakemake cluster sidecar for caching queries
to Slurm's controller/database daemons

and a configuration file `config.yaml` that defines default values for
snakemake command line arguments.

### Step1: Log onto Alpine
